{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6461b0",
   "metadata": {},
   "source": [
    "# <b><span style = \"color:#d46606; font-family:calibri\"> Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae569f",
   "metadata": {},
   "source": [
    "### <b><span style = \"color:#d46606; font-family:calibri\"> Topics Covered:\n",
    "* Understand Machine Learning Basics\n",
    "* Understanding Clasffication Metrics\n",
    "* Understand Text Feature Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a0550",
   "metadata": {},
   "source": [
    "## <b><span style = \"color:#d46606; font-family:calibri\"> Machine Learning Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e4c7cf",
   "metadata": {},
   "source": [
    "**1. Machine Learning is a method of data analysis that automates analytical model building.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d9ae5",
   "metadata": {},
   "source": [
    "**2. Using algorithms that iteratively learn from data, machine learning allows computers to find hidden insights without being exlicitly programmed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2a8a56",
   "metadata": {},
   "source": [
    "### `Supervised Learning` is commonly used in applications where historical data predicts likely future events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba2820",
   "metadata": {},
   "source": [
    "## <b><span style = \"color:#d46606; font-family:calibri\"> Machine Learning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1722b3",
   "metadata": {},
   "source": [
    "**1. Data Acquisition.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848a3a1",
   "metadata": {},
   "source": [
    "**2. Data cleaning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4774fea2",
   "metadata": {},
   "source": [
    "**3. Model Training & Building.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0090ec6",
   "metadata": {},
   "source": [
    "**4. Model Testing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c84297",
   "metadata": {},
   "source": [
    "**5. Model Deployment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f61bb5",
   "metadata": {},
   "source": [
    "### `Text classification` and `recognition` is a very common and widely applicable use of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22310951",
   "metadata": {},
   "source": [
    "## <b><span style = \"color:#d46606; font-family:calibri\"> Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b234cae",
   "metadata": {},
   "source": [
    "### After our `Machine Learning Process` is complete, we will use performac metrics to evaluate how out model did"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3419b9",
   "metadata": {},
   "source": [
    "### The Key classification metrics we need to understand are:\n",
    "* Accuracy\n",
    "* Recall\n",
    "* Precision\n",
    "* F1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe9bf6",
   "metadata": {},
   "source": [
    "## False positive is `Type 1 error` in stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d51244",
   "metadata": {},
   "source": [
    "## False Negative is `Type 2 error` in stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d5678",
   "metadata": {},
   "source": [
    "# Text Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56108de4",
   "metadata": {},
   "source": [
    "### Most of the machine learning algorithms can't take in raw text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c66196b",
   "metadata": {},
   "source": [
    "### Instead we need to perform a feature \"extraction\" from the  raw text in orderto pass numerical features to the machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7a45e",
   "metadata": {},
   "source": [
    "### For example, we count the occurance of each word to map text to a number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4fe4a9",
   "metadata": {},
   "source": [
    "## `Count Vectoriation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2b937",
   "metadata": {},
   "source": [
    "### using `from sklearn.feature_extraction.text import CountVectorizer` , we can create count vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d05367",
   "metadata": {},
   "source": [
    "### `Count Vectorizer` treats each individual word as a feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f256d5f2",
   "metadata": {},
   "source": [
    "#### Then it counts occurance of every single unique word in the document and end up creating `Document Term Matrix (DTM)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c49cb9",
   "metadata": {},
   "source": [
    "### An alternative to `CountVectorizer` is somethin called `TfidfVectorizer`. It also create a document term matrix from out messages.\n",
    "\n",
    "### However, instead of filling the DTM with token counts it calculates term frequency-inverse document frequency value  of each word `(TF-IDF)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8d5430",
   "metadata": {},
   "source": [
    "### It is the logarithmically scaled inverse fractions of the documents that contain the word(obtained by dividing the total number of documents by the numer of documents containing the term and then taking the logarithm of that quotient.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aadf40",
   "metadata": {},
   "source": [
    "## Coding example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96627c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile 1.txt\n",
    "This is a story about cats\n",
    "our feline pets\n",
    "Cats are furry animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132281dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile 2.txt\n",
    "This story is about surfing\n",
    "Catching waves is fun\n",
    "Surfing is a popular water sport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2b9c5",
   "metadata": {},
   "source": [
    "#### Building Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "565fbcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 1, 'is': 2, 'a': 3, 'story': 4, 'about': 5, 'cats': 6, 'our': 7, 'feline': 8, 'pets': 9, 'are': 10, 'furry': 11, 'animals': 12}\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "i = 1\n",
    "with open('1.txt') as f:\n",
    "    x = f.read().lower().split()\n",
    "    \n",
    "for word in x:\n",
    "    if word in vocab:\n",
    "        continue\n",
    "    else:\n",
    "        vocab[word] = i\n",
    "        i +=1\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b857188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 1, 'is': 2, 'a': 3, 'story': 4, 'about': 5, 'cats': 6, 'our': 7, 'feline': 8, 'pets': 9, 'are': 10, 'furry': 11, 'animals': 12, 'surfing': 13, 'catching': 14, 'waves': 15, 'fun': 16, 'popular': 17, 'water': 18, 'sport': 19}\n"
     ]
    }
   ],
   "source": [
    "with open('2.txt') as f:\n",
    "    x = f.read().lower().split()\n",
    "    \n",
    "for word in x:\n",
    "    if word in vocab:\n",
    "        continue\n",
    "    else:\n",
    "        vocab[word] = i\n",
    "        i +=1\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417104ad",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb9e661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.txt', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an empty vector with space for each word in the Vocubulary\n",
    "one = ['1.txt'] + [0]* len(vocab)\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1bd380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.txt', 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"1.txt\") as f:\n",
    "    x = f.read().lower().split()\n",
    "    \n",
    "for word in x:\n",
    "    one[vocab[word]]+=1\n",
    "    \n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975fa228",
   "metadata": {},
   "outputs": [],
   "source": [
    "two = ['2.txt']+[0]* len(vocab)\n",
    "\n",
    "with open('2.txt') as f:\n",
    "    x = f.read().lower().split()\n",
    "for word in x:\n",
    "    two[vocab[word]] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bf0887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.txt', 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      " ['2.txt', 1, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{one}\\n {two}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ef1e93",
   "metadata": {},
   "source": [
    "### `Bag of Words and Tf-IDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1fab30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fddd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('smsspamcollection.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60375fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "388dd1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6026270e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "209cae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "156c8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2160a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb746ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7257bd1",
   "metadata": {},
   "source": [
    "### Now we will do Count Vectorization. Text preprocessing, tokenization and ability to use stop words are all included in count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaec4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bb4682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911fb250",
   "metadata": {},
   "source": [
    "###  When we fit the data to CountVectorizer it build a vocab, count the number of word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6809f5",
   "metadata": {},
   "source": [
    "### transform makes origianl text to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08812caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af214709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3733x7082 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 49992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8292b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4bfd2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_IDF_Tran = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "741efdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tf_IDF_Tran.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3532ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6729a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9f636d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c67c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27fb604f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f5c54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "872ee1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea4fe2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180376f5",
   "metadata": {},
   "source": [
    "### We can combine everything in one single pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aff17fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c121644",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b57bccbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb463926",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "283e898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55993342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1586    7]\n",
      " [  12  234]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85312657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1593\n",
      "        spam       0.97      0.95      0.96       246\n",
      "\n",
      "    accuracy                           0.99      1839\n",
      "   macro avg       0.98      0.97      0.98      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f83d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f175d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989668297988037"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d336f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"Hi, How are you today?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19b4d9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"Congratulation you have been selected as awinner. Text WON to 442255 congratulations free entry to contest.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fb9c82",
   "metadata": {},
   "source": [
    "# `Another example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b52ea2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "205af5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"moviereviews.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50771685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74309296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f09b2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2a6fa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do films like mouse hunt get into theatres ? \r\n",
      "isn't there a law or something ? \r\n",
      "this diabolical load of claptrap from steven speilberg's dreamworks studio is hollywood family fare at its deadly worst . \r\n",
      "mouse hunt takes the bare threads of a plot and tries to prop it up with overacting and flat-out stupid slapstick that makes comedies like jingle all the way look decent by comparison . \r\n",
      "writer adam rifkin and director gore verbinski are the names chiefly responsible for this swill . \r\n",
      "the plot , for what its worth , concerns two brothers ( nathan lane and an appalling lee evens ) who inherit a poorly run string factory and a seemingly worthless house from their eccentric father . \r\n",
      "deciding to check out the long-abandoned house , they soon learn that it's worth a fortune and set about selling it in auction to the highest bidder . \r\n",
      "but battling them at every turn is a very smart mouse , happy with his run-down little abode and wanting it to stay that way . \r\n",
      "the story alternates between unfunny scenes of the brothers bickering over what to do with their inheritance and endless action sequences as the two take on their increasingly determined furry foe . \r\n",
      "whatever promise the film starts with soon deteriorates into boring dialogue , terrible overacting , and increasingly uninspired slapstick that becomes all sound and fury , signifying nothing . \r\n",
      "the script becomes so unspeakably bad that the best line poor lee evens can utter after another run in with the rodent is : \" i hate that mouse \" . \r\n",
      "oh cringe ! \r\n",
      "this is home alone all over again , and ten times worse . \r\n",
      "one touching scene early on is worth mentioning . \r\n",
      "we follow the mouse through a maze of walls and pipes until he arrives at his makeshift abode somewhere in a wall . \r\n",
      "he jumps into a tiny bed , pulls up a makeshift sheet and snuggles up to sleep , seemingly happy and just wanting to be left alone . \r\n",
      "it's a magical little moment in an otherwise soulless film . \r\n",
      "a message to speilberg : if you want dreamworks to be associated with some kind of artistic credibility , then either give all concerned in mouse hunt a swift kick up the arse or hire yourself some decent writers and directors . \r\n",
      "this kind of rubbish will just not do at all . \r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df[\"review\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d9978bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30b609d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08e9d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks = []\n",
    "\n",
    "for i , lb, rv in df.itertuples():\n",
    "    if rv.isspace():\n",
    "        blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c26fc3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57,\n",
       " 71,\n",
       " 147,\n",
       " 151,\n",
       " 283,\n",
       " 307,\n",
       " 313,\n",
       " 323,\n",
       " 343,\n",
       " 351,\n",
       " 427,\n",
       " 501,\n",
       " 633,\n",
       " 675,\n",
       " 815,\n",
       " 851,\n",
       " 977,\n",
       " 1079,\n",
       " 1299,\n",
       " 1455,\n",
       " 1493,\n",
       " 1525,\n",
       " 1531,\n",
       " 1763,\n",
       " 1851,\n",
       " 1905,\n",
       " 1993]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d1341e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(blanks, inplace=  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b0c1615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1938"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa2dc1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb519e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d1402c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d0c44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "89f8692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a999224",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_clf = Pipeline([(\"tfidf\", TfidfVectorizer()),('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "63502ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f0660c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictons = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "825a8d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3de5b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[235  47]\n",
      " [ 41 259]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ebb1830b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.83      0.84       282\n",
      "         pos       0.85      0.86      0.85       300\n",
      "\n",
      "    accuracy                           0.85       582\n",
      "   macro avg       0.85      0.85      0.85       582\n",
      "weighted avg       0.85      0.85      0.85       582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a9fed809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8487972508591065\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictons))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0af2ff",
   "metadata": {},
   "source": [
    "# Another Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac46f73",
   "metadata": {},
   "source": [
    "### Task #1: Perform imports and load the dataset into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "24ca5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3198ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"moviereviews2.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2ba1e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>I loved this movie and will watch it again. Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>A warm, touching movie that has a fantasy-like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>I was not expecting the powerful filmmaking ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>This so-called \"documentary\" tries to tell tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>This show has been my escape from reality for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   pos  I loved this movie and will watch it again. Or...\n",
       "1   pos  A warm, touching movie that has a fantasy-like...\n",
       "2   pos  I was not expecting the powerful filmmaking ex...\n",
       "3   neg  This so-called \"documentary\" tries to tell tha...\n",
       "4   pos  This show has been my escape from reality for ..."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed15ba6",
   "metadata": {},
   "source": [
    "### Task #2: Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a7359c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297c309",
   "metadata": {},
   "source": [
    "### Task #3: Remove NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3378c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64651bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4fa1a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = []\n",
    "\n",
    "\n",
    "for i , lb, rv in df.itertuples():\n",
    "    if type(rv)==str:\n",
    "        if rv.isspace():\n",
    "            blank.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "33212b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76cc41",
   "metadata": {},
   "source": [
    "### Task #4: Take a quick look at the `label` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b324366e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    2990\n",
       "neg    2990\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "70a5ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5be0e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d0f3d",
   "metadata": {},
   "source": [
    "### Task #5: Split the data into train & test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fda0b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f34cba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c62bc",
   "metadata": {},
   "source": [
    "### Task #6: Build a pipeline to vectorize the date, then train and fit a model\n",
    "You may use whatever model you like. To compare your results to the solution notebook, use `LinearSVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4f2935b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3f413e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8af1e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pip = Pipeline([('tfidf', TfidfVectorizer()),(\"clf\",LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ede5948b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pip.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5b9d0d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf_pip.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79316d14",
   "metadata": {},
   "source": [
    "### Task #7: Run predictions and analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0a7e387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8ec901ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[900,  91],\n",
       "       [ 63, 920]], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e0af4727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.93      0.91      0.92       991\n",
      "         pos       0.91      0.94      0.92       983\n",
      "\n",
      "    accuracy                           0.92      1974\n",
      "   macro avg       0.92      0.92      0.92      1974\n",
      "weighted avg       0.92      0.92      0.92      1974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c33cb835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9219858156028369"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186f276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
